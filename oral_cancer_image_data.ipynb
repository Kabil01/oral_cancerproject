{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b11f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in e:\\anaconda\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f2337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/93/21/9b035a4f823d6aee2917c75415be9a95861ff3d73a0a65e48edbf210cec1/tensorflow-2.15.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.15.0-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.15.0 from https://files.pythonhosted.org/packages/4c/48/1a5a15517f18eaa4ff8d598b1c000300b20c1bb0e624539d702117a0c369/tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in e:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\priya\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Using cached tensorflow-2.15.0-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl (300.9 MB)\n",
      "Installing collected packages: tensorflow-intel, tensorflow\n",
      "Successfully installed tensorflow-2.15.0 tensorflow-intel-2.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\PRIYA\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b073be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PRIYA\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'non-cancer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Perform one-hot encoding on the labels\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m labels_encoded \u001b[38;5;241m=\u001b[39m to_categorical(labels)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Split the dataset into training, validation, and test sets\u001b[39;00m\n\u001b[0;32m     36\u001b[0m X_train, X_temp, y_train, y_temp \u001b[38;5;241m=\u001b[39m train_test_split(images, labels_encoded, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\np_utils.py:62\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.utils.to_categorical\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_categorical\u001b[39m(y, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a class vector (integers) to binary class matrix.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    E.g. for use with `categorical_crossentropy`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    [0. 0. 0. 0.]\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Shrink the last dimension if the shape is (..., 1).\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'non-cancer'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"imageDataSet\"\n",
    "classes = [\"non-cancer\", \"cancer\"]\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load and preprocess the images\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_name)\n",
    "        # Read and resize the image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (224, 224))  # Resize to 224x224 pixels\n",
    "        # Normalize pixel values to the range [0, 1]\n",
    "        image = image / 255.0\n",
    "        images.append(image)\n",
    "        labels.append(class_name)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform one-hot encoding on the labels\n",
    "labels_encoded = to_categorical(labels)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Shuffle the training data\n",
    "shuffle_indices = np.random.permutation(len(X_train))\n",
    "X_train_shuffled = X_train[shuffle_indices]\n",
    "y_train_shuffled = y_train[shuffle_indices]\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training set shape:\", X_train_shuffled.shape, y_train_shuffled.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4b3c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (104, 224, 224, 3) (104, 2)\n",
      "Validation set shape: (13, 224, 224, 3) (13, 2)\n",
      "Test set shape: (14, 224, 224, 3) (14, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"imageDataSet\"\n",
    "classes = [\"non-cancer\", \"cancer\"]\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load and preprocess the images\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    class_label = classes.index(class_name)  # Convert class name to numerical label\n",
    "    for image_name in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_name)\n",
    "        # Read and resize the image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (224, 224))  # Resize to 224x224 pixels\n",
    "        # Normalize pixel values to the range [0, 1]\n",
    "        image = image / 255.0\n",
    "        images.append(image)\n",
    "        labels.append(class_label)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform one-hot encoding on the labels\n",
    "labels_encoded = to_categorical(labels)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Shuffle the training data\n",
    "shuffle_indices = np.random.permutation(len(X_train))\n",
    "X_train_shuffled = X_train[shuffle_indices]\n",
    "y_train_shuffled = y_train[shuffle_indices]\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training set shape:\", X_train_shuffled.shape, y_train_shuffled.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95156ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Flask in e:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in e:\\anaconda\\lib\\site-packages (from Flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in e:\\anaconda\\lib\\site-packages (from Flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in e:\\anaconda\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in e:\\anaconda\\lib\\site-packages (from Flask) (8.0.4)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from click>=8.0->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\lib\\site-packages (from Jinja2>=3.0->Flask) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f41e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
